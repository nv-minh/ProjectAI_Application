# -*- coding: utf-8 -*-
"""AIProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rEVy8KNtqdZtukWH5VTU3-cCuMGx5iMV
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)


import os
for dirname, _, filenames in os.walk('/content/sample_data'):
    for filename in filenames:
        print(os.path.join(dirname,filename))

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm
from IPython.display import Image
import warnings
warnings.filterwarnings("ignore")
# %matplotlib inline

data_path = '/content/sample_data/message_data.xlsx'

data = pd.read_excel(data_path, sheet_name = "Filter")
data.head(10)

data = data.rename(columns={"msg":"content", "class":"category"})
data

data.category.value_counts()

data.describe()

data['content'] = data['content'].astype(str)

data['length'] = data['content'].apply(len)
data.head(5)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline
data['length'].plot(bins=50, kind='hist')

data.hist(column='length', by='category', bins=50,figsize=(10,4))

count1 = Counter(" ".join(data[data['category']=='ham']["content"]).split()).most_common(20)
df1 = pd.DataFrame.from_dict(count1)
df1 = df1.rename(columns={0: "words in non-spam", 1 : "count"})
count2 = Counter(" ".join(data[data['category']=='spam']["content"]).split()).most_common(20)
df2 = pd.DataFrame.from_dict(count2)
df2 = df2.rename(columns={0: "words in spam", 1 : "count_"})

df1.plot.bar(legend = False)
y_pos = np.arange(len(df1["words in non-spam"]))
plt.xticks(y_pos, df1["words in non-spam"])
plt.title('More frequent words in non-spam messages')
plt.xlabel('words')
plt.ylabel('number')
plt.show()

df2.plot.bar(legend = False, color = 'orange')
y_pos = np.arange(len(df2["words in spam"]))
plt.xticks(y_pos, df2["words in spam"])
plt.title('More frequent words in spam messages')
plt.xlabel('words')
plt.ylabel('number')
plt.show()

data.loc[:,'category'] = data.category.map({'ham':0, 'spam':1})
print(data.shape)
data.head()

"""MODEL BUILDING"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(data['content'],
                                                    data['category'],test_size=0.20,
                                                    random_state=1)

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import CountVectorizer
count_vector = CountVectorizer()

# Fit the training data and then return the matrix
training_data = count_vector.fit_transform(X_train)

# Transform testing data and return the matrix.
testing_data = count_vector.transform(X_test)

from sklearn.naive_bayes import MultinomialNB
naive_bayes = MultinomialNB()
naive_bayes.fit(training_data,y_train)

predictions = naive_bayes.predict(testing_data)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
print('Accuracy score: {}'.format(accuracy_score(y_test, predictions)))
print('Precision score: {}'.format(precision_score(y_test, predictions)))
print('Recall score: {}'.format(recall_score(y_test, predictions)))
print('F1 score: {}'.format(f1_score(y_test, predictions)))

import joblib
from sklearn.feature_extraction.text import CountVectorizer

# Load the trained Naive Bayes model
naive_bayes = joblib.load('naive_bayes_model.pkl')

# Load the CountVectorizer used for training the model
count_vector = joblib.load('count_vectorizer.pkl')

def predict_spam_or_ham(input_string):
  # Preprocess the input string
  preprocessed_input = count_vector.transform([input_string])

  # Make the prediction
  prediction = naive_bayes.predict(preprocessed_input)

  # if prediction[0] == 1:
  #     return "spam"
  # else:
  #     return "ham"
  return prediction[0]

input_text = "Đi ngủ thôi emm ơi"
prediction =  predict_spam_or_ham(input_text)
print(f"Prediction: {prediction}")